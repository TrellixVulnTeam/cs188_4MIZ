# Creating the Training Set: Attempt #1

After receiving the data, we started our first attempt at creating a machine learning algorithm for the prostate data set. All the code discussed can be found in our Github [here](https://github.com/ardunn/cs188/blob/master/pyprostate/example_1.py). A discussion of the data received can be found [here](https://ardunn.github.io/cs188/050517). The code is written using Python 2.7 and we used [NumPy](https://docs.scipy.org/doc/numpy-dev/index.html) to interact with the MATLAB data. 

Our approach to creating the training set (`X`) was as follows:

We divided the 256x256 t2 image (see below) into `n x n` sub-images. For example, `n=4` would yield `64x64` sub-images and a training set size of 4,096 feature vectors. 

![t2 image][t2]

The feature vector would contain the pixels contained in the `n x n` sub-image. Below is the functions we wrote to create the training set: 

```python
def create_subimages(single_image, n):
    subimages = []
    for i in range(0,256, n):
        for j in range(0, 256, n):
            subimages.append(single_image[i:i+n,j:j+n])
    return subimages

def create_X(single_image, n):
    subimages = create_subimages(single_image, n)
    return [image.flatten() for image in subimages]
```

The output, or the `y`, was produced from the corresponding mask image seen below. 

![mask image][mask]

In the mask, a 2 (yellow) corresponds to the tumor, a 1 (green) corresponds to the prostate, and a 0 corresponds to the non-prostate area. 

The mask was also divided into `n x n` sub-images and the output was determined by the values in that sub-image. If a 1 or 2 was detected in the sub-image, the output vector would be a 1. If not, the output vector would be a 0. 

```python
def create_y(mask, n):
    f_vectors = create_X(mask, n)

    y = [1 if 1 in vector or 2 in vector else 0 for vector in f_vectors]
    return y
```

With our training and output set made, we ran this data through the [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from [scikit-learn](http://scikit-learn.org/stable/index.html). We attempted to use [SVM](http://scikit-learn.org/stable/modules/svm.html), however the training period was taking to long with the given data. 

We tested our model by performing a leave-out-one cross validation. We scored our model with [ROC AUC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), as this was the scoring method used by [past research](https://ardunn.github.io/cs188/literature_review). 

Below are the AUC scores we got a `n = 4, 8, 12, 16`

![scores][score]

The scores were in the 0.50 range which indicates a failure in accuracy. We asked Professor Scalzo to review out attempt and he told us the first course of action is to verify the accuracy of our dataset. Furthermore, he suggested that we build our feature vectors on a pixel basis rather than dividing the image into `n x n` sub-images. 

[Back](./)

[t2]: https://image.ibb.co/kT45xa/patient1_t2.png
[mask]: https://image.ibb.co/cbEuqv/patient1_mask.png
[score]: https://image.ibb.co/j0Pxca/image.png

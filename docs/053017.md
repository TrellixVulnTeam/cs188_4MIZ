# Filtering the Images

## Motivation

In class, we discussed how filtering can enchance images. Professor Scalzo advised us to make use of [gabor filtering](https://en.wikipedia.org/wiki/Gabor_filter) as gabor filters excel in feature extraction and texture analysis. The data from our gabor filtered image would be appended to the feature vectors in our training set. 

## The Code 

Since we were already using [scikit-learn](http://scikit-learn.org/stable/) for machine learning, we utilized [scikit-image](http://scikit-image.org/) for image processing. Specifically, we used the [gabor](http://scikit-image.org/docs/dev/api/skimage.filters.html?highlight=gabor%20filter#skimage.filters.gabor) filter function. 

We decided to play around with the gabor filter to see what type of images it produced. The following image displays Patient 0's t2 image with the gabor filtered applied across different frequencies: 

![Gabor Filter on t2][gabor_t2]

The did not anticipate these results as gabor filtered images typically look like the following: 

![Example Gabor Filtering from sci-kit][example_gabor]

The above image was pulled from scikit-image's [demo](http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_gabor.html) of gabor filters. 

We applied the gabor filter on the t2 images without normalization. We experimented with normalizing our t2 images first and received much better results: 

![Gabor Filter on Normalized t2][gabor_t2_normalized]

For `ensemble.py`, we added the following function to produced the filtered t2 images: 

```python
def get_filtered_t2(data, frequency, sigma_x=None, sigma_y=None):
    filtered_data = []
    norm_data = normalize_t2(data)
    for patient_im in norm_data:
            filt_real, filt_t2 = gabor(patient_im, frequency=frequency, sigma_x=sigma_x, sigma_y=sigma_y)
            filtered_data.append(filt_real)
    return filtered_data


```

We also created a function that would properly append the filtered t2 data to each feature vector: 

```python
def create_multiparametric_dataset(image_set, mask, n, prune=False, save_pxs=False):
    X_tot = []
    _, y = create_dataset(image_set[0], mask, n, prune=prune, save_pxs=save_pxs)

    for image in image_set:
        X, _ = create_dataset(image, mask, n, prune=prune)
        X_tot.append(X)

    X_new = []
    for i,_ in enumerate(X_tot[0]):
        Xi_new = []
        for j, _ in enumerate(X_tot):
            Xi_new += X_tot[j][i].tolist()
        X_new.append(Xi_new)

    return X_new, y
```

Finally, we added optional filtering to our `runmodel` function: 

```python
def runmodel(model, patient_index=-1, frequency=0.4, quiet=False, silent=False, normalized=False, filter_on=False,
             print_example_vector=False):
    """
    Runs a single classifier through sample classifications.
    """

    modelname = model.__class__.__name__

    if silent:
        quiet = True
    if not quiet:
        print "{model}: patient {patient}/{n_patients}: making training data".format(model=modelname, n_patients=n_patients, patient=patient_index+1)

    masks = get_masks(data)

    if normalized:
        t2 = normalize_t2(data)
    else:
        t2 = get_t2(data)

    if patient_index == -1:
        patient_index = n_patients - 1

    image_set_total = [t2]

    if filter_on:
        t2_filtered = get_filtered_t2(data, frequency=frequency)
        image_set_total.append(t2_filtered)

    X_train = []
    y_train = []

    # Create training data

    for i in range(n_patients):

        if i == patient_index:
            continue

        else:

            if len(image_set_total) > 1:
                image_set = [imset[i] for imset in image_set_total]
                X_train_single, y_train_single = create_multiparametric_dataset(image_set, masks[i], n, prune=prune)
            else:
                X_train_single, y_train_single = create_dataset(t2[i], masks[i], n, prune=prune)

            X_train += X_train_single
            y_train += y_train_single

    if print_example_vector:
        ex_vec = X_train[0]
        print "length of example vector:", len(ex_vec)
        print ex_vec

    # Create testing data

    if not quiet:
        print "{model}: patient {patient}/{n_patients}: making testing data".format(model=modelname, n_patients=n_patients, patient=patient_index+1)

    test_mask = masks[patient_index]
    test_t2 = t2[patient_index]

    if len(image_set_total) > 1:
        image_set = [imset[patient_index] for imset in image_set_total]
        X_test, y_test = create_multiparametric_dataset(image_set, test_mask, n, prune=prune, save_pxs=True)
    else:
        X_test, y_test = create_dataset(test_t2, test_mask, n, prune=prune, save_pxs=True)

    # Train, predict, and score

    if not quiet:
        print "{model}: patient {patient}/{n_patients}: training using {n_pts} points".format(model=modelname, n_patients=n_patients, patient=patient_index+1, n_pts=len(y_train))
    model.fit(X_train, y_train)

    if not quiet:
        print "{model}: patient {patient}/{n_patients}: testing using {n_pts} points".format(model=modelname, n_patients=n_patients, patient=patient_index+1, n_pts=len(y_test))
    y_pred = model.predict(X_test)

    score = roc_auc_score(y_true=y_test, y_score=y_pred)

    if not silent:
        print "{model}: patient {patient}/{n_patients}: score {score}".format(model=modelname, n_patients=n_patients, score=score, patient=patient_index+1)

    return score

```

## Results 

We ran our script at different gabor frequencies in order to determine which frequency is the best. The script was run at `n = 3` with pruning enabled: 

![GBC at Different Frequencies][frequency_influence]

Based on our experiment we found a frequency of 0.3 to be the best.


[Back](./)

[gabor_t2]: https://preview.ibb.co/hJUa3F/unnormalized_t2.png
[example_gabor]: http://scikit-image.org/docs/dev/_images/sphx_glr_plot_gabor_001.png
[gabor_t2_normalized]: https://preview.ibb.co/mf5CYF/gabor_frequencies.png
[frequency_influence]: https://image.ibb.co/etY5na/frequency_influence.png
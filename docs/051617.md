# Reviewing Our Dataset 

In our [dataset](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics), we have 62 patient folders consisting of their MRI scans and a mask that indicates the location of the prostate and the tumor. The masks were manually contoured by a clinician which left room for error. Furthermore, the quality of the scans varied among the patients. Professor Scalzo advised that we look through our dataset and only select the best patients for training. 

## Good Patients vs Bad Patients

An example of a good patient is [Patient 0](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient0): 

T2               |  Mask
:-------------------------:|:-------------------------:
![Patient 0 T2][patient0_t2]  |  ![Patient 0 Mask][patient0_mask]

The yellow section marks the cancerous area of the prostate. In the t2 image, the cancerous region is well defined by texture and intensity. In addition, the segmentation of the prostate and the tumor is properly done. 

An example of a bad patient is [Patient 9](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient9):

T2               |  Mask
:-------------------------:|:-------------------------:
![Patient 9 T2][patient9_t2]  |  ![Patient 9 Mask][patient9_mask]

For this patient, the difference between the prostate and cancerous area is indistinguishable. The entire t2 image is too dark to classify between the prostate and the cancerous area. 

Another example of patient with inaccurate contouring is [Patient 55](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient55): 

T2               |  Mask
:-------------------------:|:-------------------------:
![Patient 55 T2][patient55_t2]  |  ![Patient 55 Mask][patient55_mask]

The prostate region defined in the mask is not seen in the t2 image. 

## The Final Dataset 

We manually inspected each patient and reduced our dataset from 62 patients to 12. The selected patients are: 

* [Patient 0](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient0)
* [Patient 12](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient12)
* [Patient 18](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient18)
* [Patient 24](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient24)
* [Patient 33](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient33)
* [Patient 36](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient36)
* [Patient 3](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient3)
* [Patient 45](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient45)
* [Patient 48](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient48)
* [Patient 52](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient52)
* [Patient 58](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient58)
* [Patient 61](https://github.com/ardunn/cs188/tree/master/pyprostate/graphics/patient56)

With our reduced dataset, our next goal is to redo our data preprocessing algorithm. 

[Back](./)

[patient0_t2]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient0/patient0_t2.png
[patient0_mask]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient0/patient0_mask.png
[patient9_t2]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient9/patient9_t2.png
[patient9_mask]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient9/patient9_mask.png
[patient55_t2]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient55/patient55_t2.png
[patient55_mask]: https://raw.githubusercontent.com/ardunn/cs188/master/pyprostate/graphics/patient55/patient55_mask.png


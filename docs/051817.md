# Data Preprocessing: Attempt #2 

In this attempt, we follow Professor Scalzo's advice and created feature vectors consisting of a pixel and the surrounding pixels. 

We defined a center pixel and its surrounding pixels as the following: 

![Pixel Example][pixel_cupcake]

The feature vector consists of all the pixels inside the blue square with the pixel labeled "C" as the center pixel. The size of the subimage depends on `n`. `n` represents how far from the center pixel our subimage extends. In the example above, `n = 2`.

Since we are not interested in the non-prostate area, a pixel is discared if the center pixel lies on a pixel marked as 0 in the mask. For reference, 0 is the non-prostate area, 1 is the prostate, and 2 is the cancerous area.  In addition, we added the option to further discard pixels if any of the surrounding pixels is non-prostate.

These options are passed in as arguments to our script. The user can specify the size `n` and also specify True or False for the additional pixel discarding we described above. 

The output is determined by the center pixel's mask value. We were only interested in classifying between the cancerous and the non-cancerous area. As a result, our output was either 0 or 1: a 0 was assigned if the mask value was either 0 or 1 and a 1 was assigned if the mask value was a 2. 

We created a function `create_dataset` to create the `X` and `y` needed for training. This function creates a dataset from a single MRI image and a single mask:  

```python
def create_dataset(image, mask, n, prune=False):
    row = 1
    subimages = []
    y = []
    acpx = []
    for i in range(n, 255-n):
        for j in range(n, 255-n):
            if mask[i,j]!=0:
                # numpy submatrices have (first index starting at 0):(last index starting from 1)

                store = True
                if prune:
                    for v in mask[i-n:i+n+1, j-n:j+n+1]:
                        if 0 in v:
                            store = False
                            break

                if store:
                    subimage = image[i-n:i+n+1, j-n:j+n+1]
                    subimages.append(subimage)
                    # translate (2 -> 1) and 1 -> 0
                    yi = 1 if int(round(mask[i,j]))==2 else 0
                    y.append(yi)
                    row += 1

    X = [image.flatten() for image in subimages]
    return X, y
```

We performed the same test from our [previous attempt](https://ardunn.github.io/cs188/051117), where we measured the ROC AUC score against the following n values `n = 2, 4, 8, 16`: 

![ROC AUC Scores][score]

Once again, we used the [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from [scikit-learn](http://scikit-learn.org/stable/index.html). Compared to our previous attempt, this algorithm performed much higher and managed to reach a high score of 0.62. While this still places us in the Poor range, this attempt is a signficant improvement from before. Our next goal is to test out the various models [scikit-learn](http://scikit-learn.org/stable/index.html) offers. 

[Back](./) 

[pixel_cupcake]: https://image.ibb.co/gy1ZCa/Screen_Shot_2017_06_06_at_8_06_40_PM.png
[score]: https://preview.ibb.co/cC5i5v/Screen_Shot_2017_06_06_at_9_25_48_PM.png